{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAMER: Generative Analysis of Metadata Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a multi agent framework on Langraph to retrieve and summarize metadata information based on a user's natural language query. \n",
    "\n",
    "This workflow consists of 6 agents, or nodes, where a decision is made and there is new context provided to either the model or the user. Here are some decisions incorporated into the framework:\n",
    "1. To best answer the query, does the entire database need to be queried, or the vector index?\n",
    "- Input: `x (query)`\n",
    "- Decides best data to query against\n",
    "- Output: `entire_database, vector_embeddings`\n",
    "2. If querying against the vector embeddings, does the index need to be filtered further with metdata tags, to improve optimization of retrieval?\n",
    "- Input: `x (query)`\n",
    "- Decides whether database can be further filtered by applying a MongoDB query\n",
    "- Output: `MongoDB query, None`\n",
    "3. Are the documents retrieved during retrieval relevant to the question?\n",
    "- Input: `x (query)`\n",
    "- Decides whether document should be kept or tossed during summarization\n",
    "- Output: `yes, no`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sreya.kumar\\Documents\\GitHub\\metadata-chatbot\\venv\\Lib\\site-packages\\metadata_chatbot\\agents\\workflow.py:106: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  documents = retriever.get_relevant_documents(query = query, query_filter = filter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject information provided is:\n",
      "\n",
      "- subject_id: 662616\n",
      "- sex: Female\n",
      "- date_of_birth: 2022-11-29\n",
      "- genotype: wt/wt\n",
      "\n",
      "The acquisition information includes:\n",
      "\n",
      "- Tiles 73-83 with different channels (445nm, 488nm, 561nm) and coordinate transformations\n",
      "- Laser powers in milliwatts for each channel  \n",
      "- File names with coordinates for each tile/channel\n",
      "- Imaging angle of 0 degrees\n",
      "- Notes about laser power needing calibration\n",
      "\n",
      "There were two procedures performed:\n",
      "\n",
      "Procedure 1 (injection):\n",
      "- Injection materials included viruses SL1-hSyn-Cre, AAV1-CAG-H2B-mTurquoise2-WPRE, and AAV-Syn-DIO-TVA66T-dTomato-CVS N2cG\n",
      "- Injection coordinates and volumes provided\n",
      "\n",
      "Procedure 2 (surgery): \n",
      "- Injection material was virus EnvA CVS-N2C-histone-GFP\n",
      "- Injection coordinates and volumes provided\n",
      "\n",
      "Additional information includes specimen procedures like fixation, delipidation, and refractive index matching.\n"
     ]
    }
   ],
   "source": [
    "from metadata_chatbot.agents.GAMER import GAMER\n",
    "query = \"Can you summarize the subject and acquisition information in SmartSPIM_662616_2023-03-06_17-47-13\"\n",
    "\n",
    "model = GAMER()\n",
    "result = model.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'metadata_chatbot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmetadata_chatbot\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGAMER\u001b[39;00m \u001b[39mimport\u001b[39;00m GAMER\n\u001b[1;32m      2\u001b[0m llm \u001b[39m=\u001b[39m GAMER()\n\u001b[1;32m      3\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan you list all the procedures performed on the specimen, including their start and end dates? in SmartSPIM_662616_2023-03-06_17-47-13\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'metadata_chatbot'"
     ]
    }
   ],
   "source": [
    "from metadata_chatbot.agents.GAMER import GAMER\n",
    "llm = GAMER()\n",
    "query = \"Can you list all the procedures performed on the specimen, including their start and end dates? in SmartSPIM_662616_2023-03-06_17-47-13\"\n",
    "\n",
    "result = await llm.ainvoke(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
